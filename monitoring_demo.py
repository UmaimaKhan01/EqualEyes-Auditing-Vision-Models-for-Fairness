#!/usr/bin/env python3
"""
Simplified Real-Time Bias Monitoring Demo
Works without camera or heavy ML dependencies
"""

import json
import time
import random
from datetime import datetime
from pathlib import Path

class SimpleBiasMonitor:
    """Lightweight bias monitoring demo."""
    
    def __init__(self):
        self.monitoring_data = []
        
    def simulate_bias_detection(self, duration_seconds=10):
        """Simulate real-time bias detection."""
        
        print("üîç Starting Real-Time Bias Monitoring Demo")
        print("=" * 50)
        print("Simulating bias detection on video stream...")
        print(f"Duration: {duration_seconds} seconds")
        print()
        
        # Simulate monitoring session
        start_time = time.time()
        frame_count = 0
        
        while time.time() - start_time < duration_seconds:
            frame_count += 1
            
            # Simulate bias analysis results
            bias_score = random.uniform(0.2, 0.8)
            gender_pred = random.choice(['male', 'female'])
            confidence = random.uniform(0.7, 0.95)
            
            # Determine alert level
            if bias_score > 0.6:
                alert_level = 'HIGH'
                alert_emoji = 'üî¥'
            elif bias_score > 0.4:
                alert_level = 'MEDIUM'
                alert_emoji = 'üü°'
            else:
                alert_level = 'LOW'
                alert_emoji = 'üü¢'
            
            # Log detection
            detection = {
                'timestamp': time.time(),
                'frame': frame_count,
                'bias_score': bias_score,
                'gender_prediction': gender_pred,
                'confidence': confidence,
                'alert_level': alert_level
            }
            
            self.monitoring_data.append(detection)
            
            # Real-time output
            print(f"Frame {frame_count:3d}: {alert_emoji} Bias: {bias_score:.2f} | "
                  f"Gender: {gender_pred} ({confidence:.1%}) | Alert: {alert_level}")
            
            # Simulate processing delay
            time.sleep(0.5)
        
        print(f"\n‚úÖ Monitoring completed! Analyzed {frame_count} frames")
        
    def generate_monitoring_report(self):
        """Generate comprehensive monitoring report."""
        
        if not self.monitoring_data:
            return {'error': 'No monitoring data available'}
        
        # Calculate statistics
        bias_scores = [d['bias_score'] for d in self.monitoring_data]
        alert_levels = [d['alert_level'] for d in self.monitoring_data]
        
        # Gender distribution
        gender_counts = {}
        for d in self.monitoring_data:
            gender = d['gender_prediction']
            gender_counts[gender] = gender_counts.get(gender, 0) + 1
        
        # Alert distribution
        alert_distribution = {}
        for level in alert_levels:
            alert_distribution[level] = alert_distribution.get(level, 0) + 1
        
        report = {
            'monitoring_session': {
                'start_time': datetime.fromtimestamp(self.monitoring_data[0]['timestamp']).isoformat(),
                'end_time': datetime.fromtimestamp(self.monitoring_data[-1]['timestamp']).isoformat(),
                'duration_seconds': self.monitoring_data[-1]['timestamp'] - self.monitoring_data[0]['timestamp'],
                'total_frames': len(self.monitoring_data)
            },
            'bias_analysis': {
                'average_bias_score': sum(bias_scores) / len(bias_scores),
                'max_bias_score': max(bias_scores),
                'min_bias_score': min(bias_scores),
                'high_bias_frames': len([s for s in bias_scores if s > 0.6]),
                'bias_trend': bias_scores[-10:]  # Last 10 scores
            },
            'demographic_analysis': {
                'gender_distribution': gender_counts,
                'representation_ratio': {
                    'male_percentage': (gender_counts.get('male', 0) / len(self.monitoring_data)) * 100,
                    'female_percentage': (gender_counts.get('female', 0) / len(self.monitoring_data)) * 100
                }
            },
            'alert_summary': {
                'distribution': alert_distribution,
                'high_alerts': alert_distribution.get('HIGH', 0),
                'medium_alerts': alert_distribution.get('MEDIUM', 0),
                'low_alerts': alert_distribution.get('LOW', 0)
            },
            'recommendations': self.generate_recommendations(bias_scores, alert_levels)
        }
        
        return report
    
    def generate_recommendations(self, bias_scores, alert_levels):
        """Generate actionable recommendations."""
        recommendations = []
        
        avg_bias = sum(bias_scores) / len(bias_scores)
        high_alerts = alert_levels.count('HIGH')
        
        if avg_bias > 0.6:
            recommendations.append("High average bias detected - review content diversity")
        
        if high_alerts > len(alert_levels) * 0.3:
            recommendations.append("Frequent high-bias alerts - implement content filtering")
        
        if len(set(bias_scores[-5:])) < 2:
            recommendations.append("Bias pattern detected - diversify content sources")
        
        if not recommendations:
            recommendations.append("Monitoring within acceptable parameters")
        
        return recommendations
    
    def display_report_summary(self, report):
        """Display monitoring report summary."""
        
        print("\nüìä REAL-TIME MONITORING REPORT")
        print("=" * 50)
        
        # Session info
        session = report['monitoring_session']
        print(f"Duration: {session['duration_seconds']:.1f} seconds")
        print(f"Frames Analyzed: {session['total_frames']}")
        
        # Bias analysis
        bias = report['bias_analysis']
        print(f"\nüéØ BIAS ANALYSIS")
        print(f"Average Bias Score: {bias['average_bias_score']:.2f}")
        print(f"Max Bias Detected: {bias['max_bias_score']:.2f}")
        print(f"High-Bias Frames: {bias['high_bias_frames']}")
        
        # Demographics
        demo = report['demographic_analysis']
        print(f"\nüë• DEMOGRAPHIC DISTRIBUTION")
        for gender, count in demo['gender_distribution'].items():
            percentage = demo['representation_ratio'][f'{gender}_percentage']
            print(f"{gender.title()}: {count} frames ({percentage:.1f}%)")
        
        # Alerts
        alerts = report['alert_summary']
        print(f"\nüö® ALERT SUMMARY")
        print(f"High Alerts: {alerts['high_alerts']} üî¥")
        print(f"Medium Alerts: {alerts['medium_alerts']} üü°")
        print(f"Low Alerts: {alerts['low_alerts']} üü¢")
        
        # Recommendations
        print(f"\nüí° RECOMMENDATIONS")
        for i, rec in enumerate(report['recommendations'], 1):
            print(f"{i}. {rec}")

def main():
    """Run the simplified monitoring demo."""
    
    print("üöÄ Real-Time Bias Monitoring Demo")
    print("Advanced AI Fairness Detection System")
    print()
    
    # Initialize monitor
    monitor = SimpleBiasMonitor()
    
    # Run monitoring simulation
    monitor.simulate_bias_detection(duration_seconds=8)
    
    # Generate report
    report = monitor.generate_monitoring_report()
    
    # Save report
    with open("monitoring_report.json", "w") as f:
        json.dump(report, f, indent=2, default=str)
    
    # Display summary
    monitor.display_report_summary(report)
    
    print(f"\nüìÅ Full report saved to: monitoring_report.json")
    print("\n‚úÖ Real-time monitoring demo completed!")
    print("\nThis demonstrates:")
    print("  ‚Ä¢ Real-time bias detection capabilities")
    print("  ‚Ä¢ Live alert system with severity levels")
    print("  ‚Ä¢ Demographic analysis and reporting")
    print("  ‚Ä¢ Automated recommendations")
    print("  ‚Ä¢ Enterprise-ready monitoring dashboard")

if __name__ == "__main__":
    main()